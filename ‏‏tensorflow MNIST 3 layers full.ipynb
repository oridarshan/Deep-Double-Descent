{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aq7MqgGKBfOq"
   },
   "source": [
    "# MNIST Digit Classification with a Fully-Connected Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSmvrCh8CqZq"
   },
   "source": [
    "This notebook presents an MNIST digit classifier built with a fully-connected neural network in TensorFlow and Keras.\n",
    "\n",
    "Running 10 random subsets on different sized networks to see the \"deep double descent\" phenomenon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uzlnsvf1DGpk"
   },
   "source": [
    "## 1. Import Statements\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "l8DhknOWDIc4"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(\u001b[39m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39m#%tensorflow_version 2.x\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      7\u001b[0m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mset_seed(\u001b[39m42\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\__init__.py:469\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(_current_module, \u001b[39m\"\u001b[39m\u001b[39mkeras\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    468\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 469\u001b[0m     _keras\u001b[39m.\u001b[39;49m_load()\n\u001b[0;32m    470\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m    471\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:41\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[0;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_module_globals[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_name] \u001b[39m=\u001b[39m module\n\u001b[0;32m     44\u001b[0m \u001b[39m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\models\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\engine\\functional.py:34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m input_spec\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m node \u001b[39mas\u001b[39;00m node_module\n\u001b[1;32m---> 34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m training \u001b[39mas\u001b[39;00m training_lib\n\u001b[0;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m training_utils\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m serialization\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\engine\\training.py:45\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m \u001b[39mimport\u001b[39;00m saving_lib\n\u001b[0;32m     44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m hdf5_format\n\u001b[1;32m---> 45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m save\n\u001b[0;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m saving_utils\n\u001b[0;32m     47\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m serialization\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\saving\\legacy\\save.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m serialization\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m \u001b[39mimport\u001b[39;00m load \u001b[39mas\u001b[39;00m saved_model_load\n\u001b[1;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m \u001b[39mimport\u001b[39;00m load_context\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m \u001b[39mimport\u001b[39;00m save \u001b[39mas\u001b[39;00m saved_model_save\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m traceback_utils\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\saving\\legacy\\saved_model\\load_context.py:68\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39m\"\"\"Returns whether under a load context.\"\"\"\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_context\u001b[39m.\u001b[39min_load_context()\n\u001b[1;32m---> 68\u001b[0m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49mregister_load_context_function(in_load_context)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yuvx7u4qDQ0p"
   },
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qI70NJ8SN4An"
   },
   "source": [
    "The first step is to preprocess our data. Here, we load the MNIST digit dataset from the Keras datasets library, split it into training and test sets, reshape the matrices, and encode the labels categorically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IsaUq1mDDVLT"
   },
   "outputs": [],
   "source": [
    "# Load the MNIST dataset.\n",
    "mnist = tf.keras.datasets.mnist\n",
    "train_data, test_data = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWuEpda6EBMN"
   },
   "outputs": [],
   "source": [
    "# Divide the data into features and labels.\n",
    "train_images, train_labels = train_data\n",
    "test_images, test_labels = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wrAabZnyDinP"
   },
   "outputs": [],
   "source": [
    "# Reshape and normalize the images.\n",
    "X_train = train_images.reshape((60000, 784))\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = test_images.reshape((10000, 784))\n",
    "X_test = X_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHUWJlyBE1P0"
   },
   "outputs": [],
   "source": [
    "# Reshape the labels and encode them categorically.\n",
    "y_train = tf.keras.utils.to_categorical(train_labels)\n",
    "y_test = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVEOuuLPOJVH"
   },
   "source": [
    "Further, the following are the shapes of each matrix, as well as a visualization of a random MNIST digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9PpPi0qpNI_L",
    "outputId": "644ecbd9-6925-47fa-a5d1-33f68b2d2d96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images: (60000, 784)\n",
      "Testing Images: (10000, 784)\n",
      "Training Labels: (60000, 10)\n",
      "Test Labels: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Show the shapes of the data.\n",
    "print(\"Training Images:\", X_train.shape)\n",
    "print(\"Testing Images:\", X_test.shape)\n",
    "print(\"Training Labels:\", y_train.shape)\n",
    "print(\"Test Labels:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "mSKjBaeNNc1m",
    "outputId": "6020122d-3261-412f-ed41-2c3449cd7c64"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a sample MNIST digit.\n",
    "plt.imshow(train_images[10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decrease dataset\n",
    "To allow interpolation, which typically occurs at `n*K` where n is number of samples and K is number of classes in multicalss classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images: (4000, 784)\n",
      "Testing Images: (1000, 784)\n",
      "Training Labels: (4000, 10)\n",
      "Test Labels: (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_val_lst = []\n",
    "X_train_lst = []\n",
    "X_test_lst = []\n",
    "y_val_lst = []\n",
    "y_train_lst = []\n",
    "y_test_lst = []\n",
    "\n",
    "for i in range(10):\n",
    "    # train sample\n",
    "    train_idx = np.random.choice(60000, 4000)\n",
    "    X_train_lst.append(X_train[train_idx,:])\n",
    "    y_train_lst.append(y_train[train_idx,:])\n",
    "    # validation sample\n",
    "    val_idx = np.random.choice(60000, 1000)\n",
    "    X_val_lst.append(X_train[val_idx,:])\n",
    "    y_val_lst.append(y_train[val_idx,:])\n",
    "    # test sample\n",
    "    test_idx = np.random.choice(10000, 1000)\n",
    "    X_test_lst.append(X_test[test_idx,:])\n",
    "    y_test_lst.append(y_test[test_idx,:])\n",
    "    \n",
    "# Show the shapes of the data.\n",
    "print(\"Training Images:\", X_train_lst[0].shape)\n",
    "print(\"Testing Images:\", X_test_lst[0].shape)\n",
    "print(\"Training Labels:\", y_train_lst[0].shape)\n",
    "print(\"Test Labels:\", y_test_lst[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5ubfhUsFLR8"
   },
   "source": [
    "## 3. Neural Network\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gPoq2dRFtrH"
   },
   "source": [
    "### 3.1. Define the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jU5sDVjhOVgF"
   },
   "source": [
    "We then have to define our neural network. Here, we define a sequential model with two fully-connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ri1rSpp3FSDS"
   },
   "outputs": [],
   "source": [
    "# Define the sequential model.\n",
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try different hidden layer sizes, intepolation should occur with 10000 parameter in the net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First layer 1 to 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5CNJ9gHWFWQv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* Dataset Number 0 ***********\n",
      "\n",
      "******* Middle layer size: 1 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.4585 - accuracy: 0.3740\n",
      "32/32 [==============================] - 0s 902us/step - loss: 1.7995 - accuracy: 0.3380\n",
      "\n",
      "******* Middle layer size: 2 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8437 - accuracy: 0.7130\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5578 - accuracy: 0.5910\n",
      "\n",
      "******* Middle layer size: 3 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.8580\n",
      "32/32 [==============================] - 0s 968us/step - loss: 1.1725 - accuracy: 0.7170\n",
      "\n",
      "******* Middle layer size: 4 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1199 - accuracy: 0.9737\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 1.0549 - accuracy: 0.8050\n",
      "\n",
      "******* Middle layer size: 5 **************\n",
      "\n",
      "125/125 [==============================] - 0s 995us/step - loss: 0.0220 - accuracy: 0.9985\n",
      "32/32 [==============================] - 0s 903us/step - loss: 1.3577 - accuracy: 0.8380\n",
      "\n",
      "******* Middle layer size: 6 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.0043 - accuracy: 0.9995\n",
      "32/32 [==============================] - 0s 968us/step - loss: 1.5693 - accuracy: 0.8410\n",
      "\n",
      "******* Middle layer size: 7 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 7.9810e-04 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4518 - accuracy: 0.8660\n",
      "\n",
      "******* Middle layer size: 8 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 7.6940e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 967us/step - loss: 1.3237 - accuracy: 0.8910\n",
      "\n",
      "******* Middle layer size: 9 **************\n",
      "\n",
      "125/125 [==============================] - 0s 984us/step - loss: 2.9061e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 903us/step - loss: 1.2025 - accuracy: 0.8880\n",
      "\n",
      "******* Middle layer size: 10 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.7662e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 999us/step - loss: 1.2041 - accuracy: 0.8940\n",
      "\n",
      "******* Middle layer size: 11 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.3182e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1297 - accuracy: 0.9040\n",
      "\n",
      "******* Middle layer size: 12 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 9.5040e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 968us/step - loss: 1.0404 - accuracy: 0.9070\n",
      "\n",
      "******* Middle layer size: 13 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 8.7984e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9440 - accuracy: 0.9090\n",
      "\n",
      "******* Middle layer size: 14 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 8.1787e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 969us/step - loss: 1.0812 - accuracy: 0.9070\n",
      "\n",
      "******* Middle layer size: 15 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 5.1292e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9576 - accuracy: 0.9130\n",
      "\n",
      "******* Middle layer size: 16 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 5.3810e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0447 - accuracy: 0.9220\n",
      "\n",
      "******* Middle layer size: 17 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.9156e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9745 - accuracy: 0.9090\n",
      "\n",
      "******* Middle layer size: 18 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.0733e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0420 - accuracy: 0.9140\n",
      "\n",
      "******* Middle layer size: 19 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.3320e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9918 - accuracy: 0.9140\n",
      "\n",
      "******* Middle layer size: 20 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.1135e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0680 - accuracy: 0.9070\n",
      "\n",
      "******* Middle layer size: 21 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 3.4051e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9801 - accuracy: 0.9150\n",
      "\n",
      "******* Middle layer size: 22 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 3.2503e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8701 - accuracy: 0.9090\n",
      "\n",
      "******* Middle layer size: 23 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2.5495e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9015 - accuracy: 0.9210\n",
      "\n",
      "******* Middle layer size: 24 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2.6126e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9079 - accuracy: 0.9190\n",
      "\n",
      "******* Middle layer size: 25 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.8536e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7713 - accuracy: 0.9240\n",
      "\n",
      "******* Middle layer size: 26 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2.0368e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7315 - accuracy: 0.9250\n",
      "\n",
      "******* Middle layer size: 27 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.7695e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8218 - accuracy: 0.9170\n",
      "\n",
      "******* Middle layer size: 28 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.8912e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7543 - accuracy: 0.9190\n",
      "\n",
      "******* Middle layer size: 29 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.7415e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9556 - accuracy: 0.9190\n",
      "\n",
      "******* Middle layer size: 30 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.5423e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7687 - accuracy: 0.9310\n",
      "\n",
      "******* Middle layer size: 31 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.4688e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7642 - accuracy: 0.9250\n",
      "\n",
      "******* Middle layer size: 32 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.5171e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8000 - accuracy: 0.9240\n",
      "\n",
      "******* Middle layer size: 33 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.4961e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7561 - accuracy: 0.9260\n",
      "\n",
      "******* Middle layer size: 34 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.3499e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8776 - accuracy: 0.9180\n",
      "\n",
      "******* Middle layer size: 35 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2470e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8325 - accuracy: 0.9220\n",
      "\n",
      "******* Middle layer size: 36 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.3713e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8345 - accuracy: 0.9130\n",
      "\n",
      "******* Middle layer size: 37 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.4391e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7772 - accuracy: 0.9330\n",
      "\n",
      "******* Middle layer size: 38 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0872e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7279 - accuracy: 0.9260\n",
      "\n",
      "******* Middle layer size: 39 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1128e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.9310\n",
      "\n",
      "******* Middle layer size: 40 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1311e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7151 - accuracy: 0.9320\n",
      "\n",
      "******* Middle layer size: 41 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0780e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7504 - accuracy: 0.9220\n",
      "\n",
      "******* Middle layer size: 42 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1659e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8293 - accuracy: 0.9250\n",
      "\n",
      "******* Middle layer size: 43 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 9.4008e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6689 - accuracy: 0.9330\n",
      "\n",
      "******* Middle layer size: 44 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0214e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7416 - accuracy: 0.9370\n",
      "\n",
      "******* Middle layer size: 45 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 9.9131e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7367 - accuracy: 0.9250\n",
      "\n",
      "******* Middle layer size: 46 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 7.9810e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7039 - accuracy: 0.9210\n",
      "\n",
      "******* Middle layer size: 47 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 8.0171e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5877 - accuracy: 0.9350\n",
      "\n",
      "******* Middle layer size: 48 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 8.7172e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7393 - accuracy: 0.9230\n",
      "\n",
      "******* Middle layer size: 49 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 8.9600e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7618 - accuracy: 0.9300\n",
      "\n",
      "******* Middle layer size: 50 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 9.6148e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6783 - accuracy: 0.9250\n",
      "********* Dataset Number 1 ***********\n",
      "\n",
      "******* Middle layer size: 1 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.5650 - accuracy: 0.3702\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.8481 - accuracy: 0.3090\n",
      "\n",
      "******* Middle layer size: 2 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8583 - accuracy: 0.7230\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2923 - accuracy: 0.6320\n",
      "\n",
      "******* Middle layer size: 3 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.8683\n",
      "32/32 [==============================] - 0s 969us/step - loss: 1.0535 - accuracy: 0.7270\n",
      "\n",
      "******* Middle layer size: 4 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9703\n",
      "32/32 [==============================] - 0s 968us/step - loss: 1.0255 - accuracy: 0.8090\n",
      "\n",
      "******* Middle layer size: 5 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.9960\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 1.2658 - accuracy: 0.8360\n",
      "\n",
      "******* Middle layer size: 6 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 0.9995\n",
      "32/32 [==============================] - 0s 968us/step - loss: 1.3525 - accuracy: 0.8600\n",
      "\n",
      "******* Middle layer size: 7 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1629 - accuracy: 0.8610\n",
      "\n",
      "******* Middle layer size: 8 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.0259e-04 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4740 - accuracy: 0.8650\n",
      "\n",
      "******* Middle layer size: 9 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 5.1391e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2477 - accuracy: 0.8890\n",
      "\n",
      "******* Middle layer size: 10 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2.6043e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1357 - accuracy: 0.8900\n",
      "\n",
      "******* Middle layer size: 11 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.3664e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0923 - accuracy: 0.9050\n",
      "\n",
      "******* Middle layer size: 12 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2.4278e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2121 - accuracy: 0.9030\n",
      "\n",
      "******* Middle layer size: 13 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 9.9901e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1057 - accuracy: 0.9040\n",
      "\n",
      "******* Middle layer size: 14 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 7.1461e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 1.0077 - accuracy: 0.9000\n",
      "\n",
      "******* Middle layer size: 15 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 5.0329e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8546 - accuracy: 0.9200\n",
      "\n",
      "******* Middle layer size: 16 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.9786e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0277 - accuracy: 0.9090\n",
      "\n",
      "******* Middle layer size: 17 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.1377e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8785 - accuracy: 0.9170\n",
      "\n",
      "******* Middle layer size: 18 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 5.4195e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0481 - accuracy: 0.9140\n",
      "\n",
      "******* Middle layer size: 19 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 3.2480e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.8389 - accuracy: 0.9140\n",
      "\n",
      "******* Middle layer size: 20 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 3.3484e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8270 - accuracy: 0.9100\n",
      "\n",
      "******* Middle layer size: 21 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 3.6457e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9526 - accuracy: 0.9100\n",
      "\n",
      "******* Middle layer size: 22 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2.5585e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8223 - accuracy: 0.9170\n",
      "\n",
      "******* Middle layer size: 23 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2.7606e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9901 - accuracy: 0.9100\n",
      "\n",
      "******* Middle layer size: 24 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2.9364e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9793 - accuracy: 0.9190\n",
      "\n",
      "******* Middle layer size: 25 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2.2843e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8483 - accuracy: 0.9150\n",
      "\n",
      "******* Middle layer size: 26 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2.4389e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8196 - accuracy: 0.9170\n",
      "\n",
      "******* Middle layer size: 27 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.6911e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.9280\n",
      "\n",
      "******* Middle layer size: 28 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.8332e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7614 - accuracy: 0.9220\n",
      "\n",
      "******* Middle layer size: 29 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.6032e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8151 - accuracy: 0.9220\n",
      "\n",
      "******* Middle layer size: 30 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.6321e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7794 - accuracy: 0.9260\n",
      "\n",
      "******* Middle layer size: 31 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.4264e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6980 - accuracy: 0.9260\n",
      "\n",
      "******* Middle layer size: 32 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.3753e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6564 - accuracy: 0.9240\n",
      "\n",
      "******* Middle layer size: 33 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2839e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.9310\n",
      "\n",
      "******* Middle layer size: 34 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.3441e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6388 - accuracy: 0.9290\n",
      "\n",
      "******* Middle layer size: 35 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.4013e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8702 - accuracy: 0.9210\n",
      "\n",
      "******* Middle layer size: 36 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.3038e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8146 - accuracy: 0.9190\n",
      "\n",
      "******* Middle layer size: 37 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2171e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6681 - accuracy: 0.9380\n",
      "\n",
      "******* Middle layer size: 38 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1370e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6636 - accuracy: 0.9280\n",
      "\n",
      "******* Middle layer size: 39 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0987e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6997 - accuracy: 0.9210\n",
      "\n",
      "******* Middle layer size: 40 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0672e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6752 - accuracy: 0.9320\n",
      "\n",
      "******* Middle layer size: 41 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1609e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7200 - accuracy: 0.9260\n",
      "\n",
      "******* Middle layer size: 42 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2042e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7694 - accuracy: 0.9270\n",
      "\n",
      "******* Middle layer size: 43 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0021e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7192 - accuracy: 0.9270\n",
      "\n",
      "******* Middle layer size: 44 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.5661e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.9290\n",
      "\n",
      "******* Middle layer size: 45 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.3066e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6536 - accuracy: 0.9330\n",
      "\n",
      "******* Middle layer size: 46 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 8.6048e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.9250\n",
      "\n",
      "******* Middle layer size: 47 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.8107e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.9230\n",
      "\n",
      "******* Middle layer size: 48 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.9547e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7216 - accuracy: 0.9330\n",
      "\n",
      "******* Middle layer size: 49 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 8.3175e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.9280\n",
      "\n",
      "******* Middle layer size: 50 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 9.1162e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6284 - accuracy: 0.9350\n",
      "********* Dataset Number 2 ***********\n",
      "\n",
      "******* Middle layer size: 1 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.4833 - accuracy: 0.3860\n",
      "32/32 [==============================] - 0s 968us/step - loss: 1.7525 - accuracy: 0.3420\n",
      "\n",
      "******* Middle layer size: 2 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9779 - accuracy: 0.6505\n",
      "32/32 [==============================] - 0s 968us/step - loss: 1.5099 - accuracy: 0.5510\n",
      "\n",
      "******* Middle layer size: 3 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.3959 - accuracy: 0.8780\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 1.0285 - accuracy: 0.7230\n",
      "\n",
      "******* Middle layer size: 4 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.9772\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3325 - accuracy: 0.7940\n",
      "\n",
      "******* Middle layer size: 5 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9985\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2479 - accuracy: 0.8260\n",
      "\n",
      "******* Middle layer size: 6 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.9625\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9702 - accuracy: 0.7970\n",
      "\n",
      "******* Middle layer size: 7 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.0365e-04 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3553 - accuracy: 0.8680\n",
      "\n",
      "******* Middle layer size: 8 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 7.8992e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5506 - accuracy: 0.8760\n",
      "\n",
      "******* Middle layer size: 9 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 6.1142e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4197 - accuracy: 0.8780\n",
      "\n",
      "******* Middle layer size: 10 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2.4070e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3456 - accuracy: 0.8920\n",
      "\n",
      "******* Middle layer size: 11 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.7497e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3232 - accuracy: 0.8990\n",
      "\n",
      "******* Middle layer size: 12 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1622e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1946 - accuracy: 0.8860\n",
      "\n",
      "******* Middle layer size: 13 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0746e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1690 - accuracy: 0.8980\n",
      "\n",
      "******* Middle layer size: 14 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 9.3238e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0886 - accuracy: 0.9010\n",
      "\n",
      "******* Middle layer size: 15 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.8392e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9407 - accuracy: 0.9050\n",
      "\n",
      "******* Middle layer size: 16 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 7.5521e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1430 - accuracy: 0.9000\n",
      "\n",
      "******* Middle layer size: 17 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.0719e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9077 - accuracy: 0.9170\n",
      "\n",
      "******* Middle layer size: 18 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.1325e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9974 - accuracy: 0.9130\n",
      "\n",
      "******* Middle layer size: 19 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.6436e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0579 - accuracy: 0.9030\n",
      "\n",
      "******* Middle layer size: 20 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 3.1133e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0017 - accuracy: 0.9110\n",
      "\n",
      "******* Middle layer size: 21 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.2175e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9318 - accuracy: 0.9180\n",
      "\n",
      "******* Middle layer size: 22 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 3.0962e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8737 - accuracy: 0.9090\n",
      "\n",
      "******* Middle layer size: 23 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.1965e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9602 - accuracy: 0.9120\n",
      "\n",
      "******* Middle layer size: 24 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2.4254e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8732 - accuracy: 0.9090\n",
      "\n",
      "******* Middle layer size: 25 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.9908e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9021 - accuracy: 0.9150\n",
      "\n",
      "******* Middle layer size: 26 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2.0138e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8789 - accuracy: 0.9150\n",
      "\n",
      "******* Middle layer size: 27 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.7045e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7856 - accuracy: 0.9140\n",
      "\n",
      "******* Middle layer size: 28 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.7769e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7108 - accuracy: 0.9240\n",
      "\n",
      "******* Middle layer size: 29 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.4380e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7634 - accuracy: 0.9300\n",
      "\n",
      "******* Middle layer size: 30 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5651e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8175 - accuracy: 0.9140\n",
      "\n",
      "******* Middle layer size: 31 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5345e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8015 - accuracy: 0.9240\n",
      "\n",
      "******* Middle layer size: 32 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.6163e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7856 - accuracy: 0.9140\n",
      "\n",
      "******* Middle layer size: 33 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5623e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8439 - accuracy: 0.9140\n",
      "\n",
      "******* Middle layer size: 34 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.3040e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7079 - accuracy: 0.9200\n",
      "\n",
      "******* Middle layer size: 35 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.3913e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6414 - accuracy: 0.9230\n",
      "\n",
      "******* Middle layer size: 36 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.5017e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8060 - accuracy: 0.9200\n",
      "\n",
      "******* Middle layer size: 37 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1417e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6769 - accuracy: 0.9140\n",
      "\n",
      "******* Middle layer size: 38 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.3161e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7267 - accuracy: 0.9280\n",
      "\n",
      "******* Middle layer size: 39 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0437e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.9240\n",
      "\n",
      "******* Middle layer size: 40 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2719e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8099 - accuracy: 0.9210\n",
      "\n",
      "******* Middle layer size: 41 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0484e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7371 - accuracy: 0.9220\n",
      "\n",
      "******* Middle layer size: 42 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.1141e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7311 - accuracy: 0.9230\n",
      "\n",
      "******* Middle layer size: 43 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.3485e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8973 - accuracy: 0.9130\n",
      "\n",
      "******* Middle layer size: 44 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.7653e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6572 - accuracy: 0.9270\n",
      "\n",
      "******* Middle layer size: 45 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0106e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7136 - accuracy: 0.9260\n",
      "\n",
      "******* Middle layer size: 46 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.5200e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7398 - accuracy: 0.9240\n",
      "\n",
      "******* Middle layer size: 47 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.2044e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.9290\n",
      "\n",
      "******* Middle layer size: 48 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.6882e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.9250\n",
      "\n",
      "******* Middle layer size: 49 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.7376e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7427 - accuracy: 0.9200\n",
      "\n",
      "******* Middle layer size: 50 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.6309e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.9260\n",
      "********* Dataset Number 3 ***********\n",
      "\n",
      "******* Middle layer size: 1 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.5345 - accuracy: 0.3643\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.8584 - accuracy: 0.2900\n",
      "\n",
      "******* Middle layer size: 2 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8104 - accuracy: 0.7117\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3873 - accuracy: 0.6020\n",
      "\n",
      "******* Middle layer size: 3 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.3648 - accuracy: 0.8830\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9073 - accuracy: 0.7670\n",
      "\n",
      "******* Middle layer size: 4 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1293 - accuracy: 0.9653\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1951 - accuracy: 0.8010\n",
      "\n",
      "******* Middle layer size: 5 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9980\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1415 - accuracy: 0.8490\n",
      "\n",
      "******* Middle layer size: 6 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 0.9995\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4725 - accuracy: 0.8610\n",
      "\n",
      "******* Middle layer size: 7 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.6850e-04 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1901 - accuracy: 0.8830\n",
      "\n",
      "******* Middle layer size: 8 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0510e-04 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2192 - accuracy: 0.8710\n",
      "\n",
      "******* Middle layer size: 9 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 5.5859e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0307 - accuracy: 0.8930\n",
      "\n",
      "******* Middle layer size: 10 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 3.5211e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0433 - accuracy: 0.9030\n",
      "\n",
      "******* Middle layer size: 11 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2.0660e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0844 - accuracy: 0.9070\n",
      "\n",
      "******* Middle layer size: 12 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0294e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9723 - accuracy: 0.9060\n",
      "\n",
      "******* Middle layer size: 13 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0383e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9751 - accuracy: 0.9040\n",
      "\n",
      "******* Middle layer size: 14 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0211e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9577 - accuracy: 0.9020\n",
      "\n",
      "******* Middle layer size: 15 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 5.7477e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8888 - accuracy: 0.9110\n",
      "\n",
      "******* Middle layer size: 16 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 3.9575e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8248 - accuracy: 0.9270\n",
      "\n",
      "******* Middle layer size: 17 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.5115e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8731 - accuracy: 0.9060\n",
      "\n",
      "******* Middle layer size: 18 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.4399e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8821 - accuracy: 0.9040\n",
      "\n",
      "******* Middle layer size: 19 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.3710e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8058 - accuracy: 0.9160\n",
      "\n",
      "******* Middle layer size: 20 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 3.5363e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8157 - accuracy: 0.9130\n",
      "\n",
      "******* Middle layer size: 21 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.4241e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8399 - accuracy: 0.9170\n",
      "\n",
      "******* Middle layer size: 22 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.6755e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8229 - accuracy: 0.9210\n",
      "\n",
      "******* Middle layer size: 23 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2.8701e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7735 - accuracy: 0.9240\n",
      "\n",
      "******* Middle layer size: 24 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.5113e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7536 - accuracy: 0.9250\n",
      "\n",
      "******* Middle layer size: 25 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.3892e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7288 - accuracy: 0.9230\n",
      "\n",
      "******* Middle layer size: 26 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5997e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5940 - accuracy: 0.9350\n",
      "\n",
      "******* Middle layer size: 27 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.6578e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.9400\n",
      "\n",
      "******* Middle layer size: 28 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.7568e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7075 - accuracy: 0.9270\n",
      "\n",
      "******* Middle layer size: 29 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5884e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6646 - accuracy: 0.9170\n",
      "\n",
      "******* Middle layer size: 30 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.6772e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.9320\n",
      "\n",
      "******* Middle layer size: 31 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.6375e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7184 - accuracy: 0.9220\n",
      "\n",
      "******* Middle layer size: 32 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.7112e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7155 - accuracy: 0.9250\n",
      "\n",
      "******* Middle layer size: 33 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.3678e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7302 - accuracy: 0.9320\n",
      "\n",
      "******* Middle layer size: 34 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.4573e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7157 - accuracy: 0.9200\n",
      "\n",
      "******* Middle layer size: 35 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.4728e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7457 - accuracy: 0.9160\n",
      "\n",
      "******* Middle layer size: 36 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5874e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6573 - accuracy: 0.9290\n",
      "\n",
      "******* Middle layer size: 37 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.5013e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.9490\n",
      "\n",
      "******* Middle layer size: 38 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.1602e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.9310\n",
      "\n",
      "******* Middle layer size: 39 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.8756e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.9400\n",
      "\n",
      "******* Middle layer size: 40 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2234e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.9300\n",
      "\n",
      "******* Middle layer size: 41 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.4145e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.9400\n",
      "\n",
      "******* Middle layer size: 42 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2746e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7508 - accuracy: 0.9170\n",
      "\n",
      "******* Middle layer size: 43 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.0933e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6294 - accuracy: 0.9300\n",
      "\n",
      "******* Middle layer size: 44 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0077e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.9340\n",
      "\n",
      "******* Middle layer size: 45 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.4463e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.9300\n",
      "\n",
      "******* Middle layer size: 46 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.7642e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.9380\n",
      "\n",
      "******* Middle layer size: 47 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.4516e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.9350\n",
      "\n",
      "******* Middle layer size: 48 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.6640e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.9380\n",
      "\n",
      "******* Middle layer size: 49 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.5507e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.9450\n",
      "\n",
      "******* Middle layer size: 50 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.5264e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.9320\n",
      "********* Dataset Number 4 ***********\n",
      "\n",
      "******* Middle layer size: 1 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.5887 - accuracy: 0.3503\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.9228 - accuracy: 0.3200\n",
      "\n",
      "******* Middle layer size: 2 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8161 - accuracy: 0.7243\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3440 - accuracy: 0.6060\n",
      "\n",
      "******* Middle layer size: 3 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.8920\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1771 - accuracy: 0.7560\n",
      "\n",
      "******* Middle layer size: 4 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1669 - accuracy: 0.9555\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1719 - accuracy: 0.7980\n",
      "\n",
      "******* Middle layer size: 5 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.9492\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1568 - accuracy: 0.7960\n",
      "\n",
      "******* Middle layer size: 6 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4923 - accuracy: 0.8460\n",
      "\n",
      "******* Middle layer size: 7 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.7527e-04 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.9241 - accuracy: 0.8560\n",
      "\n",
      "******* Middle layer size: 8 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2491e-04 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5776 - accuracy: 0.8810\n",
      "\n",
      "******* Middle layer size: 9 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0406e-04 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4043 - accuracy: 0.8870\n",
      "\n",
      "******* Middle layer size: 10 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.9962e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2513 - accuracy: 0.8860\n",
      "\n",
      "******* Middle layer size: 11 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.1266e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4928 - accuracy: 0.8840\n",
      "\n",
      "******* Middle layer size: 12 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.6868e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3495 - accuracy: 0.8810\n",
      "\n",
      "******* Middle layer size: 13 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2549e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3216 - accuracy: 0.8990\n",
      "\n",
      "******* Middle layer size: 14 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 7.5106e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2301 - accuracy: 0.8900\n",
      "\n",
      "******* Middle layer size: 15 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 9.1973e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3008 - accuracy: 0.8870\n",
      "\n",
      "******* Middle layer size: 16 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 6.7276e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2359 - accuracy: 0.8920\n",
      "\n",
      "******* Middle layer size: 17 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 6.9962e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1511 - accuracy: 0.8990\n",
      "\n",
      "******* Middle layer size: 18 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 5.4834e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.2032 - accuracy: 0.8920\n",
      "\n",
      "******* Middle layer size: 19 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.1175e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0131 - accuracy: 0.9050\n",
      "\n",
      "******* Middle layer size: 20 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.2516e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2611 - accuracy: 0.8990\n",
      "\n",
      "******* Middle layer size: 21 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.9566e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8461 - accuracy: 0.9050\n",
      "\n",
      "******* Middle layer size: 22 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2.9770e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1108 - accuracy: 0.9060\n",
      "\n",
      "******* Middle layer size: 23 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.7624e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0453 - accuracy: 0.8920\n",
      "\n",
      "******* Middle layer size: 24 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.5796e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9236 - accuracy: 0.9020\n",
      "\n",
      "******* Middle layer size: 25 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.9412e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0967 - accuracy: 0.8940\n",
      "\n",
      "******* Middle layer size: 26 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.9551e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9763 - accuracy: 0.9060\n",
      "\n",
      "******* Middle layer size: 27 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.1002e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0606 - accuracy: 0.9050\n",
      "\n",
      "******* Middle layer size: 28 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.8641e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8739 - accuracy: 0.9040\n",
      "\n",
      "******* Middle layer size: 29 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.1723e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9947 - accuracy: 0.8990\n",
      "\n",
      "******* Middle layer size: 30 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5931e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9488 - accuracy: 0.9120\n",
      "\n",
      "******* Middle layer size: 31 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.0556e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0726 - accuracy: 0.8930\n",
      "\n",
      "******* Middle layer size: 32 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.4459e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8548 - accuracy: 0.9130\n",
      "\n",
      "******* Middle layer size: 33 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5831e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9439 - accuracy: 0.9090\n",
      "\n",
      "******* Middle layer size: 34 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.4364e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9404 - accuracy: 0.9060\n",
      "\n",
      "******* Middle layer size: 35 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5115e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8887 - accuracy: 0.9080\n",
      "\n",
      "******* Middle layer size: 36 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.6746e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9588 - accuracy: 0.8980\n",
      "\n",
      "******* Middle layer size: 37 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.1479e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8237 - accuracy: 0.9090\n",
      "\n",
      "******* Middle layer size: 38 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2895e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8615 - accuracy: 0.9070\n",
      "\n",
      "******* Middle layer size: 39 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2766e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8415 - accuracy: 0.9100\n",
      "\n",
      "******* Middle layer size: 40 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0897e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8114 - accuracy: 0.9180\n",
      "\n",
      "******* Middle layer size: 41 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.3625e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9333 - accuracy: 0.9040\n",
      "\n",
      "******* Middle layer size: 42 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2024e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9279 - accuracy: 0.9130\n",
      "\n",
      "******* Middle layer size: 43 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0634e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8713 - accuracy: 0.9200\n",
      "\n",
      "******* Middle layer size: 44 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.8566e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.9280\n",
      "\n",
      "******* Middle layer size: 45 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.1288e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8594 - accuracy: 0.9120\n",
      "\n",
      "******* Middle layer size: 46 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.1865e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7436 - accuracy: 0.9170\n",
      "\n",
      "******* Middle layer size: 47 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.5634e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8128 - accuracy: 0.9150\n",
      "\n",
      "******* Middle layer size: 48 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.5448e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8306 - accuracy: 0.9170\n",
      "\n",
      "******* Middle layer size: 49 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.7169e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7081 - accuracy: 0.9210\n",
      "\n",
      "******* Middle layer size: 50 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.3282e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7550 - accuracy: 0.9180\n",
      "********* Dataset Number 5 ***********\n",
      "\n",
      "******* Middle layer size: 1 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.4871 - accuracy: 0.3647\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.7834 - accuracy: 0.2760\n",
      "\n",
      "******* Middle layer size: 2 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9780 - accuracy: 0.6008\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.6962 - accuracy: 0.4700\n",
      "\n",
      "******* Middle layer size: 3 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.3779 - accuracy: 0.8950\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0024 - accuracy: 0.7640\n",
      "\n",
      "******* Middle layer size: 4 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1683 - accuracy: 0.9572\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1246 - accuracy: 0.7920\n",
      "\n",
      "******* Middle layer size: 5 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 0.9992\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4262 - accuracy: 0.8330\n",
      "\n",
      "******* Middle layer size: 6 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2325 - accuracy: 0.8540\n",
      "\n",
      "******* Middle layer size: 7 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.4194e-04 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2767 - accuracy: 0.8740\n",
      "\n",
      "******* Middle layer size: 8 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 8.3520e-04 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1947 - accuracy: 0.8710\n",
      "\n",
      "******* Middle layer size: 9 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 3.3760e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2108 - accuracy: 0.8900\n",
      "\n",
      "******* Middle layer size: 10 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.4728e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2401 - accuracy: 0.8890\n",
      "\n",
      "******* Middle layer size: 11 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2.3441e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1934 - accuracy: 0.8930\n",
      "\n",
      "******* Middle layer size: 12 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 9.9220e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8859 - accuracy: 0.9110\n",
      "\n",
      "******* Middle layer size: 13 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2285e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8299 - accuracy: 0.9050\n",
      "\n",
      "******* Middle layer size: 14 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2669e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0818 - accuracy: 0.9040\n",
      "\n",
      "******* Middle layer size: 15 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0996e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0831 - accuracy: 0.9030\n",
      "\n",
      "******* Middle layer size: 16 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 5.2110e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8108 - accuracy: 0.9180\n",
      "\n",
      "******* Middle layer size: 17 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 5.1919e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9410 - accuracy: 0.9140\n",
      "\n",
      "******* Middle layer size: 18 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 3.9325e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8933 - accuracy: 0.8980\n",
      "\n",
      "******* Middle layer size: 19 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 3.0685e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7702 - accuracy: 0.9120\n",
      "\n",
      "******* Middle layer size: 20 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 3.1187e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7492 - accuracy: 0.9200\n",
      "\n",
      "******* Middle layer size: 21 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.1125e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8127 - accuracy: 0.9120\n",
      "\n",
      "******* Middle layer size: 22 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.1840e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8644 - accuracy: 0.9140\n",
      "\n",
      "******* Middle layer size: 23 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.8957e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7972 - accuracy: 0.9220\n",
      "\n",
      "******* Middle layer size: 24 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.3083e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7113 - accuracy: 0.9330\n",
      "\n",
      "******* Middle layer size: 25 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.0838e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8530 - accuracy: 0.9180\n",
      "\n",
      "******* Middle layer size: 26 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.1857e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7789 - accuracy: 0.9230\n",
      "\n",
      "******* Middle layer size: 27 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.1792e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7729 - accuracy: 0.9210\n",
      "\n",
      "******* Middle layer size: 28 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.9629e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7213 - accuracy: 0.9280\n",
      "\n",
      "******* Middle layer size: 29 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.7330e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7116 - accuracy: 0.9260\n",
      "\n",
      "******* Middle layer size: 30 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.6594e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.9290\n",
      "\n",
      "******* Middle layer size: 31 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.6960e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7502 - accuracy: 0.9210\n",
      "\n",
      "******* Middle layer size: 32 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.6568e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.9220\n",
      "\n",
      "******* Middle layer size: 33 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5516e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7871 - accuracy: 0.9250\n",
      "\n",
      "******* Middle layer size: 34 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2940e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6785 - accuracy: 0.9220\n",
      "\n",
      "******* Middle layer size: 35 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2577e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.9290\n",
      "\n",
      "******* Middle layer size: 36 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0538e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.9330\n",
      "\n",
      "******* Middle layer size: 37 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2447e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6297 - accuracy: 0.9280\n",
      "\n",
      "******* Middle layer size: 38 **************\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2912e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6042 - accuracy: 0.9320\n",
      "\n",
      "******* Middle layer size: 39 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.3966e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7210 - accuracy: 0.9310\n",
      "\n",
      "******* Middle layer size: 40 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0976e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.9270\n",
      "\n",
      "******* Middle layer size: 41 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2540e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7274 - accuracy: 0.9180\n",
      "\n",
      "******* Middle layer size: 42 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0390e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.9360\n",
      "\n",
      "******* Middle layer size: 43 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.4127e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.9350\n",
      "\n",
      "******* Middle layer size: 44 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.4041e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.9420\n",
      "\n",
      "******* Middle layer size: 45 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.1991e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.9250\n",
      "\n",
      "******* Middle layer size: 46 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.7388e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.9290\n",
      "\n",
      "******* Middle layer size: 47 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.8609e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.9380\n",
      "\n",
      "******* Middle layer size: 48 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.9968e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.9350\n",
      "\n",
      "******* Middle layer size: 49 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.0444e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.9290\n",
      "\n",
      "******* Middle layer size: 50 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.1083e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.9420\n",
      "********* Dataset Number 6 ***********\n",
      "\n",
      "******* Middle layer size: 1 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.5392 - accuracy: 0.3675\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.8206 - accuracy: 0.3130\n",
      "\n",
      "******* Middle layer size: 2 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.7301 - accuracy: 0.7405\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2396 - accuracy: 0.6470\n",
      "\n",
      "******* Middle layer size: 3 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.3402 - accuracy: 0.8920\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2736 - accuracy: 0.7450\n",
      "\n",
      "******* Middle layer size: 4 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1019 - accuracy: 0.9790\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0774 - accuracy: 0.8310\n",
      "\n",
      "******* Middle layer size: 5 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9937\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5475 - accuracy: 0.8380\n",
      "\n",
      "******* Middle layer size: 6 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.0078 - accuracy: 0.9998\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4415 - accuracy: 0.8550\n",
      "\n",
      "******* Middle layer size: 7 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.8998e-04 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.7125 - accuracy: 0.8760\n",
      "\n",
      "******* Middle layer size: 8 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1001e-04 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4972 - accuracy: 0.8880\n",
      "\n",
      "******* Middle layer size: 9 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 7.4518e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3745 - accuracy: 0.8900\n",
      "\n",
      "******* Middle layer size: 10 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 3.2290e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3656 - accuracy: 0.9040\n",
      "\n",
      "******* Middle layer size: 11 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.4656e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.4429 - accuracy: 0.8940\n",
      "\n",
      "******* Middle layer size: 12 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1513e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.1426 - accuracy: 0.9020\n",
      "\n",
      "******* Middle layer size: 13 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 9.3415e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4466 - accuracy: 0.9020\n",
      "\n",
      "******* Middle layer size: 14 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.5699e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3527 - accuracy: 0.9020\n",
      "\n",
      "******* Middle layer size: 15 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 6.3887e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0817 - accuracy: 0.9080\n",
      "\n",
      "******* Middle layer size: 16 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.2816e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0015 - accuracy: 0.9130\n",
      "\n",
      "******* Middle layer size: 17 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 4.0383e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0546 - accuracy: 0.9200\n",
      "\n",
      "******* Middle layer size: 18 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 5.3886e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.2504 - accuracy: 0.9020\n",
      "\n",
      "******* Middle layer size: 19 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 3.8967e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1331 - accuracy: 0.9140\n",
      "\n",
      "******* Middle layer size: 20 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 3.0846e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.9621 - accuracy: 0.9120\n",
      "\n",
      "******* Middle layer size: 21 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.2811e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.2377 - accuracy: 0.9090\n",
      "\n",
      "******* Middle layer size: 22 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.5313e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.2572 - accuracy: 0.9030\n",
      "\n",
      "******* Middle layer size: 23 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.0836e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8354 - accuracy: 0.9230\n",
      "\n",
      "******* Middle layer size: 24 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.6606e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.1598 - accuracy: 0.9080\n",
      "\n",
      "******* Middle layer size: 25 **************\n",
      "\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 2.3807e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.0074 - accuracy: 0.9220\n",
      "\n",
      "******* Middle layer size: 26 **************\n",
      "\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.5439e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.1924 - accuracy: 0.9140\n",
      "\n",
      "******* Middle layer size: 27 **************\n",
      "\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.8481e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8732 - accuracy: 0.9300\n",
      "\n",
      "******* Middle layer size: 28 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.8702e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0165 - accuracy: 0.9180\n",
      "\n",
      "******* Middle layer size: 29 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.6840e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9480 - accuracy: 0.9220\n",
      "\n",
      "******* Middle layer size: 30 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.6298e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8393 - accuracy: 0.9200\n",
      "\n",
      "******* Middle layer size: 31 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5292e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9668 - accuracy: 0.9250\n",
      "\n",
      "******* Middle layer size: 32 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.6419e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0299 - accuracy: 0.9110\n",
      "\n",
      "******* Middle layer size: 33 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5815e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9016 - accuracy: 0.9170\n",
      "\n",
      "******* Middle layer size: 34 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.4624e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9419 - accuracy: 0.9230\n",
      "\n",
      "******* Middle layer size: 35 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.6709e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0307 - accuracy: 0.9190\n",
      "\n",
      "******* Middle layer size: 36 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.4779e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9088 - accuracy: 0.9190\n",
      "\n",
      "******* Middle layer size: 37 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0828e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8983 - accuracy: 0.9250\n",
      "\n",
      "******* Middle layer size: 38 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2271e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7992 - accuracy: 0.9230\n",
      "\n",
      "******* Middle layer size: 39 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0562e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9121 - accuracy: 0.9250\n",
      "\n",
      "******* Middle layer size: 40 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.1258e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8880 - accuracy: 0.9220\n",
      "\n",
      "******* Middle layer size: 41 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2270e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0188 - accuracy: 0.9190\n",
      "\n",
      "******* Middle layer size: 42 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.1587e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8818 - accuracy: 0.9210\n",
      "\n",
      "******* Middle layer size: 43 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0388e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8973 - accuracy: 0.9210\n",
      "\n",
      "******* Middle layer size: 44 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0632e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8729 - accuracy: 0.9290\n",
      "\n",
      "******* Middle layer size: 45 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0398e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8601 - accuracy: 0.9200\n",
      "\n",
      "******* Middle layer size: 46 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.6137e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8424 - accuracy: 0.9250\n",
      "\n",
      "******* Middle layer size: 47 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.9522e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8751 - accuracy: 0.9240\n",
      "\n",
      "******* Middle layer size: 48 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.8012e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7878 - accuracy: 0.9290\n",
      "\n",
      "******* Middle layer size: 49 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.6857e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8416 - accuracy: 0.9210\n",
      "\n",
      "******* Middle layer size: 50 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.9985e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8333 - accuracy: 0.9230\n",
      "********* Dataset Number 7 ***********\n",
      "\n",
      "******* Middle layer size: 1 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.5753 - accuracy: 0.3560\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.8012 - accuracy: 0.3350\n",
      "\n",
      "******* Middle layer size: 2 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.7897 - accuracy: 0.7345\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2073 - accuracy: 0.6670\n",
      "\n",
      "******* Middle layer size: 3 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.3773 - accuracy: 0.8780\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0361 - accuracy: 0.7720\n",
      "\n",
      "******* Middle layer size: 4 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1472 - accuracy: 0.9653\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2023 - accuracy: 0.8190\n",
      "\n",
      "******* Middle layer size: 5 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.0403 - accuracy: 0.9940\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5218 - accuracy: 0.8070\n",
      "\n",
      "******* Middle layer size: 6 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.1826 - accuracy: 0.8600\n",
      "\n",
      "******* Middle layer size: 7 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.2106e-04 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2349 - accuracy: 0.8840\n",
      "\n",
      "******* Middle layer size: 8 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.4192e-04 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.1934 - accuracy: 0.8900\n",
      "\n",
      "******* Middle layer size: 9 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.3909e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.1120 - accuracy: 0.8900\n",
      "\n",
      "******* Middle layer size: 10 **************\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 2ms/step - loss: 2.8322e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9733 - accuracy: 0.9070\n",
      "\n",
      "******* Middle layer size: 11 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2799e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8327 - accuracy: 0.9070\n",
      "\n",
      "******* Middle layer size: 12 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.3254e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0025 - accuracy: 0.9070\n",
      "\n",
      "******* Middle layer size: 13 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 8.7379e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9711 - accuracy: 0.9000\n",
      "\n",
      "******* Middle layer size: 14 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.4445e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0062 - accuracy: 0.9080\n",
      "\n",
      "******* Middle layer size: 15 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0119e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0684 - accuracy: 0.9060\n",
      "\n",
      "******* Middle layer size: 16 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.0623e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0344 - accuracy: 0.9080\n",
      "\n",
      "******* Middle layer size: 17 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.5375e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9116 - accuracy: 0.9230\n",
      "\n",
      "******* Middle layer size: 18 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.7691e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8327 - accuracy: 0.9080\n",
      "\n",
      "******* Middle layer size: 19 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.6521e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7701 - accuracy: 0.9120\n",
      "\n",
      "******* Middle layer size: 20 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 3.7127e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7924 - accuracy: 0.9130\n",
      "\n",
      "******* Middle layer size: 21 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.6567e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8596 - accuracy: 0.9150\n",
      "\n",
      "******* Middle layer size: 22 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.6892e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7918 - accuracy: 0.9210\n",
      "\n",
      "******* Middle layer size: 23 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.0822e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9824 - accuracy: 0.9180\n",
      "\n",
      "******* Middle layer size: 24 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.5355e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7906 - accuracy: 0.9210\n",
      "\n",
      "******* Middle layer size: 25 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.3477e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7262 - accuracy: 0.9190\n",
      "\n",
      "******* Middle layer size: 26 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.0193e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.9350\n",
      "\n",
      "******* Middle layer size: 27 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.1623e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7151 - accuracy: 0.9280\n",
      "\n",
      "******* Middle layer size: 28 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.2708e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8120 - accuracy: 0.9170\n",
      "\n",
      "******* Middle layer size: 29 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.8071e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7107 - accuracy: 0.9290\n",
      "\n",
      "******* Middle layer size: 30 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.6069e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7053 - accuracy: 0.9260\n",
      "\n",
      "******* Middle layer size: 31 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5063e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7583 - accuracy: 0.9260\n",
      "\n",
      "******* Middle layer size: 32 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.8529e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7843 - accuracy: 0.9240\n",
      "\n",
      "******* Middle layer size: 33 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.7920e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7430 - accuracy: 0.9190\n",
      "\n",
      "******* Middle layer size: 34 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.4861e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.9310\n",
      "\n",
      "******* Middle layer size: 35 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.4819e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7483 - accuracy: 0.9250\n",
      "\n",
      "******* Middle layer size: 36 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.4551e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.9250\n",
      "\n",
      "******* Middle layer size: 37 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0503e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6450 - accuracy: 0.9270\n",
      "\n",
      "******* Middle layer size: 38 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.3318e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.9290\n",
      "\n",
      "******* Middle layer size: 39 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.3522e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7645 - accuracy: 0.9210\n",
      "\n",
      "******* Middle layer size: 40 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2569e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.9370\n",
      "\n",
      "******* Middle layer size: 41 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.0497e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.9360\n",
      "\n",
      "******* Middle layer size: 42 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2151e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.9350\n",
      "\n",
      "******* Middle layer size: 43 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.1783e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6467 - accuracy: 0.9270\n",
      "\n",
      "******* Middle layer size: 44 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0126e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7188 - accuracy: 0.9280\n",
      "\n",
      "******* Middle layer size: 45 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.1101e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.9360\n",
      "\n",
      "******* Middle layer size: 46 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.5856e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6301 - accuracy: 0.9270\n",
      "\n",
      "******* Middle layer size: 47 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.4665e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.9330\n",
      "\n",
      "******* Middle layer size: 48 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.2134e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6197 - accuracy: 0.9310\n",
      "\n",
      "******* Middle layer size: 49 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.1386e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.9320\n",
      "\n",
      "******* Middle layer size: 50 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.1843e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.9350\n",
      "********* Dataset Number 8 ***********\n",
      "\n",
      "******* Middle layer size: 1 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.5931 - accuracy: 0.3587\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.8323 - accuracy: 0.3350\n",
      "\n",
      "******* Middle layer size: 2 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8610 - accuracy: 0.6845\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2578 - accuracy: 0.5660\n",
      "\n",
      "******* Middle layer size: 3 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8530\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9563 - accuracy: 0.7370\n",
      "\n",
      "******* Middle layer size: 4 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9460\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9965 - accuracy: 0.7780\n",
      "\n",
      "******* Middle layer size: 5 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.9937\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.2051 - accuracy: 0.8200\n",
      "\n",
      "******* Middle layer size: 6 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 0.9992\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.3744 - accuracy: 0.8200\n",
      "\n",
      "******* Middle layer size: 7 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.9005e-04 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.3676 - accuracy: 0.8600\n",
      "\n",
      "******* Middle layer size: 8 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 9.8546e-04 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3502 - accuracy: 0.8570\n",
      "\n",
      "******* Middle layer size: 9 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.5213e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4779 - accuracy: 0.8580\n",
      "\n",
      "******* Middle layer size: 10 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.2650e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4168 - accuracy: 0.8780\n",
      "\n",
      "******* Middle layer size: 11 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.2544e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.2944 - accuracy: 0.8750\n",
      "\n",
      "******* Middle layer size: 12 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2421e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.2447 - accuracy: 0.8850\n",
      "\n",
      "******* Middle layer size: 13 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.3611e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.3158 - accuracy: 0.8890\n",
      "\n",
      "******* Middle layer size: 14 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.6306e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0921 - accuracy: 0.8850\n",
      "\n",
      "******* Middle layer size: 15 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.3563e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.2112 - accuracy: 0.8990\n",
      "\n",
      "******* Middle layer size: 16 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.1206e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.1136 - accuracy: 0.8920\n",
      "\n",
      "******* Middle layer size: 17 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.7083e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0730 - accuracy: 0.8970\n",
      "\n",
      "******* Middle layer size: 18 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.7190e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1324 - accuracy: 0.8930\n",
      "\n",
      "******* Middle layer size: 19 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.7159e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9793 - accuracy: 0.9030\n",
      "\n",
      "******* Middle layer size: 20 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.5877e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0305 - accuracy: 0.9050\n",
      "\n",
      "******* Middle layer size: 21 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.0306e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9090 - accuracy: 0.8940\n",
      "\n",
      "******* Middle layer size: 22 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.7637e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9222 - accuracy: 0.9030\n",
      "\n",
      "******* Middle layer size: 23 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.2742e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8421 - accuracy: 0.9080\n",
      "\n",
      "******* Middle layer size: 24 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.3842e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9013 - accuracy: 0.9070\n",
      "\n",
      "******* Middle layer size: 25 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.2737e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8960 - accuracy: 0.8970\n",
      "\n",
      "******* Middle layer size: 26 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.9319e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8546 - accuracy: 0.9120\n",
      "\n",
      "******* Middle layer size: 27 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.2932e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9370 - accuracy: 0.8970\n",
      "\n",
      "******* Middle layer size: 28 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.8892e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9519 - accuracy: 0.8960\n",
      "\n",
      "******* Middle layer size: 29 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.8614e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9129 - accuracy: 0.9030\n",
      "\n",
      "******* Middle layer size: 30 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5365e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8460 - accuracy: 0.9020\n",
      "\n",
      "******* Middle layer size: 31 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.6462e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8960 - accuracy: 0.8980\n",
      "\n",
      "******* Middle layer size: 32 **************\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 2ms/step - loss: 1.6275e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9423 - accuracy: 0.9090\n",
      "\n",
      "******* Middle layer size: 33 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2376e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8064 - accuracy: 0.9100\n",
      "\n",
      "******* Middle layer size: 34 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5369e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8910 - accuracy: 0.9010\n",
      "\n",
      "******* Middle layer size: 35 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.4445e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8947 - accuracy: 0.9090\n",
      "\n",
      "******* Middle layer size: 36 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.3545e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8393 - accuracy: 0.9100\n",
      "\n",
      "******* Middle layer size: 37 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.3418e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8180 - accuracy: 0.9030\n",
      "\n",
      "******* Middle layer size: 38 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.2407e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8034 - accuracy: 0.9130\n",
      "\n",
      "******* Middle layer size: 39 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0635e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7177 - accuracy: 0.9130\n",
      "\n",
      "******* Middle layer size: 40 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0446e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7811 - accuracy: 0.9120\n",
      "\n",
      "******* Middle layer size: 41 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.1349e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7742 - accuracy: 0.9170\n",
      "\n",
      "******* Middle layer size: 42 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.1425e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8525 - accuracy: 0.9110\n",
      "\n",
      "******* Middle layer size: 43 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.5594e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7818 - accuracy: 0.9060\n",
      "\n",
      "******* Middle layer size: 44 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.1118e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8437 - accuracy: 0.9100\n",
      "\n",
      "******* Middle layer size: 45 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0492e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7578 - accuracy: 0.9130\n",
      "\n",
      "******* Middle layer size: 46 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.6112e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8423 - accuracy: 0.9150\n",
      "\n",
      "******* Middle layer size: 47 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.8860e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7982 - accuracy: 0.9110\n",
      "\n",
      "******* Middle layer size: 48 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.2031e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7191 - accuracy: 0.9170\n",
      "\n",
      "******* Middle layer size: 49 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.1776e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7781 - accuracy: 0.9090\n",
      "\n",
      "******* Middle layer size: 50 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.5963e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7303 - accuracy: 0.9180\n",
      "********* Dataset Number 9 ***********\n",
      "\n",
      "******* Middle layer size: 1 **************\n",
      "\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.5222 - accuracy: 0.3778\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.7371 - accuracy: 0.3210\n",
      "\n",
      "******* Middle layer size: 2 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.8429 - accuracy: 0.7067\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1861 - accuracy: 0.6000\n",
      "\n",
      "******* Middle layer size: 3 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8857\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9356 - accuracy: 0.7670\n",
      "\n",
      "******* Middle layer size: 4 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.9467\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9974 - accuracy: 0.7810\n",
      "\n",
      "******* Middle layer size: 5 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.9962\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.2491 - accuracy: 0.8200\n",
      "\n",
      "******* Middle layer size: 6 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.3466 - accuracy: 0.8400\n",
      "\n",
      "******* Middle layer size: 7 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.5431e-04 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.3655 - accuracy: 0.8750\n",
      "\n",
      "******* Middle layer size: 8 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.4262e-04 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.2066 - accuracy: 0.8830\n",
      "\n",
      "******* Middle layer size: 9 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.6242e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2008 - accuracy: 0.8900\n",
      "\n",
      "******* Middle layer size: 10 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.2707e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0870 - accuracy: 0.8960\n",
      "\n",
      "******* Middle layer size: 11 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.0266e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.1229 - accuracy: 0.8920\n",
      "\n",
      "******* Middle layer size: 12 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.1600e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9095 - accuracy: 0.9110\n",
      "\n",
      "******* Middle layer size: 13 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.1700e-05 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9743 - accuracy: 0.8950\n",
      "\n",
      "******* Middle layer size: 14 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.4195e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9023 - accuracy: 0.9050\n",
      "\n",
      "******* Middle layer size: 15 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.9607e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8684 - accuracy: 0.9080\n",
      "\n",
      "******* Middle layer size: 16 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.8237e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9517 - accuracy: 0.8950\n",
      "\n",
      "******* Middle layer size: 17 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.1173e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8927 - accuracy: 0.9120\n",
      "\n",
      "******* Middle layer size: 18 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.5079e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9030 - accuracy: 0.9050\n",
      "\n",
      "******* Middle layer size: 19 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.7733e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8936 - accuracy: 0.9100\n",
      "\n",
      "******* Middle layer size: 20 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.6992e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8943 - accuracy: 0.9150\n",
      "\n",
      "******* Middle layer size: 21 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.7310e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.9230\n",
      "\n",
      "******* Middle layer size: 22 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.1167e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8636 - accuracy: 0.9090\n",
      "\n",
      "******* Middle layer size: 23 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.2514e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7705 - accuracy: 0.9190\n",
      "\n",
      "******* Middle layer size: 24 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.5211e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8963 - accuracy: 0.9070\n",
      "\n",
      "******* Middle layer size: 25 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.8762e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8039 - accuracy: 0.9150\n",
      "\n",
      "******* Middle layer size: 26 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.5213e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.7755 - accuracy: 0.9170\n",
      "\n",
      "******* Middle layer size: 27 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.9000e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7771 - accuracy: 0.9200\n",
      "\n",
      "******* Middle layer size: 28 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5006e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.9280\n",
      "\n",
      "******* Middle layer size: 29 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.7233e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6618 - accuracy: 0.9240\n",
      "\n",
      "******* Middle layer size: 30 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4802e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6501 - accuracy: 0.9290\n",
      "\n",
      "******* Middle layer size: 31 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.3335e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6977 - accuracy: 0.9300\n",
      "\n",
      "******* Middle layer size: 32 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.5216e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.9270\n",
      "\n",
      "******* Middle layer size: 33 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.6989e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7762 - accuracy: 0.9150\n",
      "\n",
      "******* Middle layer size: 34 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.3822e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6452 - accuracy: 0.9310\n",
      "\n",
      "******* Middle layer size: 35 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5106e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.9210\n",
      "\n",
      "******* Middle layer size: 36 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.3386e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7825 - accuracy: 0.9220\n",
      "\n",
      "******* Middle layer size: 37 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.3572e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7761 - accuracy: 0.9220\n",
      "\n",
      "******* Middle layer size: 38 **************\n",
      "\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2172e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6640 - accuracy: 0.9300\n",
      "\n",
      "******* Middle layer size: 39 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0791e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.9240\n",
      "\n",
      "******* Middle layer size: 40 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.1758e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.9280\n",
      "\n",
      "******* Middle layer size: 41 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0365e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.9280\n",
      "\n",
      "******* Middle layer size: 42 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.2449e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6889 - accuracy: 0.9160\n",
      "\n",
      "******* Middle layer size: 43 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0168e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6874 - accuracy: 0.9220\n",
      "\n",
      "******* Middle layer size: 44 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.0494e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.9320\n",
      "\n",
      "******* Middle layer size: 45 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.4345e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5850 - accuracy: 0.9310\n",
      "\n",
      "******* Middle layer size: 46 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.0974e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.9280\n",
      "\n",
      "******* Middle layer size: 47 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.8852e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6762 - accuracy: 0.9330\n",
      "\n",
      "******* Middle layer size: 48 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.4256e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7388 - accuracy: 0.9210\n",
      "\n",
      "******* Middle layer size: 49 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.2414e-07 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6959 - accuracy: 0.9270\n",
      "\n",
      "******* Middle layer size: 50 **************\n",
      "\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0245e-06 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.9220\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters.\n",
    "num_epochs = 1000\n",
    "batch_size = 256\n",
    "\n",
    "mean_layer_size_list = np.zeros(50)\n",
    "mean_train_loss_list = np.zeros(50)\n",
    "mean_test_loss_list = np.zeros(50)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"********* Dataset Number {i} ***********\")\n",
    "    layer_size_list = []\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "    # Try different hidden layer sizes\n",
    "    for net_size in range(1, 51):\n",
    "        # Define the sequential model.\n",
    "        model = tf.keras.models.Sequential()\n",
    "        # Add two fully-connected layers to the network.\n",
    "        model.add(tf.keras.layers.Dense(net_size, activation='relu', input_shape=(28 * 28,)))\n",
    "        model.add(tf.keras.layers.Dense(2, activation='relu', input_shape=(28 * 28,)))\n",
    "        model.add(tf.keras.layers.Dense(2, activation='relu', input_shape=(28 * 28,)))\n",
    "        model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "        # Compile the model.\n",
    "        model.compile(optimizer= 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        #model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the model.\n",
    "        print('\\n******* Middle layer size: {} **************\\n'.format(net_size))\n",
    "        history = model.fit(X_train_lst[i], \n",
    "                              y_train_lst[i], \n",
    "                              epochs=num_epochs, \n",
    "                              batch_size=batch_size, \n",
    "                              validation_data=(X_val_lst[i], y_val_lst[i]),\n",
    "                              verbose=0)\n",
    "        # Save train and test accuracy\n",
    "        train_loss, train_accuracy = model.evaluate(X_train_lst[i], y_train_lst[i])\n",
    "        test_loss, test_accuracy = model.evaluate(X_test_lst[i], y_test_lst[i])\n",
    "        layer_size_list.append(net_size)\n",
    "        train_loss_list.append(train_loss)\n",
    "        test_loss_list.append(test_loss)\n",
    "    \n",
    "    # save stats\n",
    "    mean_layer_size_list += layer_size_list\n",
    "    mean_train_loss_list += train_loss_list\n",
    "    mean_test_loss_list += test_loss_list\n",
    "\n",
    "mean_layer_size_list /= 10\n",
    "mean_train_loss_list /= 10\n",
    "mean_test_loss_list /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and test loss.\n",
    "x = np.arange(0, num_epochs, 1)\n",
    "plt.title('Training and Test Loss')\n",
    "plt.xlabel('net size')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(layer_size_list, mean_train_loss_list, label='Training Loss')\n",
    "plt.plot(layer_size_list, mean_test_loss_list, label='Test Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOtUl0jm0CM4G+U6wQaGTlq",
   "name": "MNIST Digit Classification with a Fully-Connected Neural Network",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3da6b625537c82abb50b76383c9633b0c4e1a1a1f73e620b7d684119a72ebf7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
